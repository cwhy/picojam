{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import functools\n",
    "from typing import Callable\n",
    "from better_partial import _, partial\n",
    "from jax import vmap\n",
    "\n",
    "\n",
    "def compose(f, g):\n",
    "    return lambda *args, **kw: g(f(*args, **kw))\n",
    "\n",
    "class PointFreeFunction:\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "        functools.update_wrapper(self, func)\n",
    "    \n",
    "    def f(self, *args, **kw):\n",
    "        return PointFreeFunction(partial(self.func)(*args, **kw))\n",
    "    \n",
    "    def vmap(self, *args, **kw):\n",
    "        return PointFreeFunction(vmap(self.func, *args, **kw))\n",
    "\n",
    "    def __call__(self, *args, **kw):\n",
    "        return self.func(*args, **kw)\n",
    "    \n",
    "    def __rshift__(self, other: 'PointFreeFunction' | Callable):\n",
    "        if isinstance(other, PointFreeFunction):\n",
    "            return PointFreeFunction(compose(self.func, other.func))\n",
    "        elif callable(other):\n",
    "            return PointFreeFunction(compose(self.func, other))\n",
    "        else:\n",
    "            raise TypeError(\"other must be callable or PointFreeFunction\")\n",
    "\n",
    "F = PointFreeFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.nn import sigmoid\n",
    "from jax.numpy.linalg import norm\n",
    "from jax.numpy import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def affine(x, W, b):\n",
    "    return W.T @ x + b\n",
    "\n",
    "def swish(x):\n",
    "    return x * sigmoid(x)\n",
    "\n",
    "def sglu(x, wv, wu, wo):\n",
    "    v = x @ wv\n",
    "    u = x @ wu\n",
    "    return (v * u) @ wo\n",
    "\n",
    "def rmsn(x, d):\n",
    "    return  x / (norm(x)/ sqrt(d))\n",
    "\n",
    "def mglu(x, ws):\n",
    "    for w in ws:\n",
    "        sglu_w = F(sglu).f(_, **w['sglu'])\n",
    "        x = rmsn(sglu_w(x), **w['rmsn'])\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal_init_std = 0.01\n",
    "#\n",
    "# #W1 = init_utils.zerO_init_2D((d_in, d_h1))\n",
    "# W1 = init_utils.normal_init(next(key_gen), normal_init_std, (d_in, d_h1))\n",
    "# b1 = zeros((d_h1))\n",
    "# #W2 = init_utils.zerO_init_2D((d_h1, d_out))\n",
    "# W2 = init_utils.normal_init(next(key_gen), normal_init_std, (d_h1, d_out))\n",
    "# b2 = zeros((d_out))\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../berries\")\n",
    "import init_utils, random_utils\n",
    "from init_utils import zerO_init_2D\n",
    "from jax.random import split\n",
    "\n",
    "\n",
    "def sglu_config(d_in, d_h, d_out, init):\n",
    "    return {\n",
    "        \"wv\": {\n",
    "            \"size\": (d_in, d_h),\n",
    "            \"init\": init,\n",
    "        },\n",
    "        \"wu\": {\n",
    "            \"size\": (d_in, d_h),\n",
    "            \"init\": init,\n",
    "        },\n",
    "        \"wo\": {\n",
    "            \"size\": (d_h, d_out),\n",
    "            \"init\": init,\n",
    "        },\n",
    "    }\n",
    "\n",
    "def rmsn_config(d_out):\n",
    "    return {\n",
    "        \"d\": {\n",
    "            \"const\": d_out,\n",
    "        }\n",
    "    }\n",
    "\n",
    "def mglu_layer_config(d_in, d_h, d_out, init):\n",
    "    return {\n",
    "        \"sglu\": sglu_config(d_in, d_h, d_out, init),\n",
    "        \"rmsn\": rmsn_config(d_out),\n",
    "    }\n",
    "\n",
    "\n",
    "def mglu_config(d_in, d_h_layer, d_out, d_h, n_layers, init):\n",
    "    return tuple([\n",
    "        mglu_layer_config(d_in, d_h, d_h_layer, init),\n",
    "        *[mglu_layer_config(d_h_layer, d_h, d_h_layer, init)] * (n_layers - 1),\n",
    "        mglu_layer_config(d_h_layer, d_h, d_out, init),\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "seed = 0\n",
    "key_gen = random_utils.infinite_safe_keys(seed)\n",
    "\n",
    "\n",
    "def init_weight(key, init, size):\n",
    "    if init[\"type\"] == \"normal\":\n",
    "        return init_utils.normal_init(key, init[\"std\"], size)\n",
    "    elif init[\"type\"] == \"zer0\":\n",
    "        return zerO_init_2D(size)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown init type: {init['type']}\")\n",
    "\n",
    "\n",
    "def init_weights(key, configs):\n",
    "    if isinstance(configs, tuple):\n",
    "        keys = key.split(len(configs))\n",
    "        return tuple(init_weights(k, c) for c, k in zip(configs, keys))\n",
    "    elif isinstance(configs, dict):\n",
    "        if \"const\" in configs:\n",
    "            return configs[\"const\"]\n",
    "        if \"init\" in configs:\n",
    "            return init_weight(key, **configs)\n",
    "        else:\n",
    "            keys = key.split(len(configs))\n",
    "            return {name: init_weights(k, config) for (name, config), k in zip(configs.items(), keys)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "mnist = load_dataset(\"mnist\").with_format(\"jax\")\n",
    "mnistData = mnist['train']\n",
    "X_img = mnistData['image']\n",
    "y = mnistData['label']\n",
    "X_img_test = mnist[\"test\"][\"image\"]\n",
    "n_test_samples = X_img_test.shape[0]\n",
    "X_test = X_img_test.reshape((n_test_samples, -1))\n",
    "y_test = mnist[\"test\"][\"label\"]\n",
    "n_samples, _, _ = X_img.shape\n",
    "X = X_img.reshape((n_samples, -1))\n",
    "n_samples, d_in = X.shape\n",
    "d_out = len(set(y.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_h_layer = 128\n",
    "d_h = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.303737\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import optax\n",
    "from jax.numpy import mean\n",
    "from jax import grad, jit\n",
    "from jax.tree_util import tree_map\n",
    "from better_partial import _\n",
    "\n",
    "def accuracy(logits, y):\n",
    "    return (logits.argmax(-1) == y).mean()\n",
    "\n",
    "\n",
    "mglu_b = F(mglu).vmap((0, None, None), 0)\n",
    "\n",
    "def sce_loss(to_logits, x, y, W):\n",
    "    return optax.softmax_cross_entropy_with_integer_labels(to_logits(x, W), y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "loss_b_all = F(sce_loss).f(mglu, _, _, _).vmap((0, 0, None), 0)\n",
    "loss_d = loss_b_all.f(X, y, _)\n",
    "loss_b_d = loss_d >> mean\n",
    "\n",
    "lr = 0.001\n",
    "mask_fn = lambda p: tree_map(lambda x: not isinstance(x, int), p)\n",
    "opt = optax.multi_transform({\"sgd\": optax.rmsprop(lr), \"zero\": optax.set_to_zero()}, mask_fn)\n",
    "\n",
    "\n",
    "method = {\"type\": \"zer0\", \"std\": 0.001}\n",
    "# method = {\"type\": \"normal\", \"std\": 0.01}\n",
    "W = init_weights(next(key_gen), mglu_config(d_in, d_h_layer, d_out, d_h, 2, method))\n",
    "loss0 = loss_b_d(W)\n",
    "print(loss0)\n",
    "state = opt.init(W)\n",
    "\n",
    "@jit\n",
    "def update(W, opt_state):\n",
    "    grads = grad(loss_b_d)(W)\n",
    "    updates, opt_state = opt.update(grads, opt_state)\n",
    "    new_W = optax.apply_updates(W, updates)\n",
    "    return new_W, opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "grad requires real- or complex-valued inputs (input dtype that is a sub-dtype of np.inexact), but got int32. If you want to use Boolean- or integer-valued inputs, use vjp or set allow_int to True.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m get_accuracy_b_t \u001b[38;5;241m=\u001b[39m get_accuracy_b\u001b[38;5;241m.\u001b[39mf(X_test, y_test, _) \u001b[38;5;241m>>\u001b[39m mean\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m----> 9\u001b[0m     W, state \u001b[38;5;241m=\u001b[39m \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m50\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28mprint\u001b[39m(get_accuracy_b_d(W), get_accuracy_b_t(W), loss_b_d(W))\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[127], line 37\u001b[0m, in \u001b[0;36mupdate\u001b[0;34m(W, opt_state)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;129m@jit\u001b[39m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(W, opt_state):\n\u001b[0;32m---> 37\u001b[0m     grads \u001b[38;5;241m=\u001b[39m \u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_b_d\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     updates, opt_state \u001b[38;5;241m=\u001b[39m opt\u001b[38;5;241m.\u001b[39mupdate(grads, opt_state)\n\u001b[1;32m     39\u001b[0m     new_W \u001b[38;5;241m=\u001b[39m optax\u001b[38;5;241m.\u001b[39mapply_updates(W, updates)\n",
      "    \u001b[0;31m[... skipping hidden 4 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Projects/picojam/pico/.venv/lib/python3.10/site-packages/jax/_src/api.py:774\u001b[0m, in \u001b[0;36m_check_input_dtype_revderiv\u001b[0;34m(name, holomorphic, allow_int, x)\u001b[0m\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (dtypes\u001b[38;5;241m.\u001b[39missubdtype(aval\u001b[38;5;241m.\u001b[39mdtype, dtypes\u001b[38;5;241m.\u001b[39mextended) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    771\u001b[0m     dtypes\u001b[38;5;241m.\u001b[39missubdtype(aval\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minteger) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    772\u001b[0m     dtypes\u001b[38;5;241m.\u001b[39missubdtype(aval\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mbool_)):\n\u001b[1;32m    773\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_int:\n\u001b[0;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires real- or complex-valued inputs (input dtype \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    775\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthat is a sub-dtype of np.inexact), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maval\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    776\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you want to use Boolean- or integer-valued inputs, use vjp \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    777\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor set allow_int to True.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtypes\u001b[38;5;241m.\u001b[39missubdtype(aval\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minexact):\n\u001b[1;32m    779\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires numerical-valued inputs (input dtype that is a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    780\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msub-dtype of np.bool_ or np.number), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maval\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: grad requires real- or complex-valued inputs (input dtype that is a sub-dtype of np.inexact), but got int32. If you want to use Boolean- or integer-valued inputs, use vjp or set allow_int to True."
     ]
    }
   ],
   "source": [
    "\n",
    "def get_accuracy(x, y, W):\n",
    "    return accuracy(mglu(x, W), y)\n",
    "\n",
    "get_accuracy_b = F(get_accuracy).vmap(in_axes=(0, 0, None), out_axes=0)\n",
    "get_accuracy_b_d = get_accuracy_b.f(X, y, _) >> mean\n",
    "get_accuracy_b_t = get_accuracy_b.f(X_test, y_test, _) >> mean\n",
    "\n",
    "for i in range(1000):\n",
    "    W, state = update(W, state)\n",
    "    if i % 50 == 0:\n",
    "        print(get_accuracy_b_d(W), get_accuracy_b_t(W), loss_b_d(W))\n",
    "print(loss_d(W))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
