{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../berries\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/owner/Projects/picojam/pico/.venv/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for mnist contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mnist\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "mnist = load_dataset(\"mnist\").with_format(\"jax\")\n",
    "mnistData = mnist['train']\n",
    "X_img = mnistData['image']\n",
    "y = mnistData['label']\n",
    "X_img_test = mnist[\"test\"][\"image\"]\n",
    "n_test_samples = X_img_test.shape[0]\n",
    "X_test = X_img_test.reshape((n_test_samples, -1))\n",
    "y_test = mnist[\"test\"][\"label\"]\n",
    "n_samples, _, _ = X_img.shape\n",
    "X = X_img.reshape((n_samples, -1))\n",
    "n_samples, d_x = X.shape\n",
    "d_y = len(set(y.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_h_layer = 128\n",
    "d_h = 64\n",
    "n_layers = 1\n",
    "d_in = d_x\n",
    "# d_out = d_y\n",
    "d_out = d_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7283.9497\n",
      "tuple:\n",
      "    sglu:\n",
      "        wv:\n",
      "            array shape: (784, 64)\n",
      "        wu:\n",
      "            array shape: (784, 64)\n",
      "        wo:\n",
      "            array shape: (64, 128)\n",
      "        total params: 108544\n",
      "    rmsn:\n",
      "        d:\n",
      "            128.0\n",
      "        total params: 1\n",
      "    total params: 108545\n",
      "tuple:\n",
      "    sglu:\n",
      "        wv:\n",
      "            array shape: (128, 64)\n",
      "        wu:\n",
      "            array shape: (128, 64)\n",
      "        wo:\n",
      "            array shape: (64, 784)\n",
      "        total params: 66560\n",
      "    rmsn:\n",
      "        d:\n",
      "            784.0\n",
      "        total params: 1\n",
      "    total params: 66561\n",
      "total params: 175106\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import optax\n",
    "from jax.numpy import mean\n",
    "from jax import grad, jit\n",
    "from jax.tree_util import tree_map\n",
    "from pf import F, _\n",
    "# import nn\n",
    "# import importlib\n",
    "# importlib.reload(nn)\n",
    "import random_utils\n",
    "from nn import mglu_config, mglu, init_weights, fmt_weights\n",
    "\n",
    "seed = 0\n",
    "key_gen = random_utils.infinite_safe_keys(seed)\n",
    "\n",
    "def accuracy(logits, y):\n",
    "    return (logits.argmax(-1) == y).mean()\n",
    "\n",
    "\n",
    "mglu_b = F(mglu).vmap((0, None, None), 0)\n",
    "\n",
    "def sce_loss(to_logits, x, y, W):\n",
    "    return optax.softmax_cross_entropy_with_integer_labels(to_logits(x, W), y)\n",
    "\n",
    "def l2_loss(to_logits, x, W):\n",
    "    return ((to_logits(x, W) - x) ** 2).mean()\n",
    "\n",
    "\n",
    "\n",
    "loss_b_all = F(l2_loss).f(mglu,  _, _).vmap((0, None), 0)\n",
    "loss_d = loss_b_all.f(X, _)\n",
    "loss_b_d = loss_d >> mean\n",
    "\n",
    "lr = 0.001\n",
    "mask_fn = lambda p: tree_map(lambda x: not isinstance(x, int), p)\n",
    "# opt = optax.multi_transform({\"sgd\": optax.rmsprop(lr), \"zero\": optax.set_to_zero()}, mask_fn)\n",
    "opt = optax.masked(optax.rmsprop(lr), mask_fn)\n",
    "\n",
    "\n",
    "method = {\"type\": \"zer0\", \"std\": 0.001}\n",
    "# method = {\"type\": \"normal\", \"std\": 0.01}\n",
    "W = init_weights(next(key_gen), mglu_config(d_in, d_h_layer, d_out, d_h, n_layers, method))\n",
    "loss0 = loss_b_d(W)\n",
    "print(loss0)\n",
    "print(fmt_weights(W)[0])\n",
    "state = opt.init(W)\n",
    "\n",
    "@jit\n",
    "def update(W, opt_state):\n",
    "    grads = grad(loss_b_d)(W)\n",
    "    updates, opt_state = opt.update(grads, opt_state)\n",
    "    new_W = optax.apply_updates(W, updates)\n",
    "    return new_W, opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00075 0.0008 7244.5195\n",
      "0.0 0.0 7174.575\n",
      "1.6666667e-05 0.0 7158.53\n",
      "0.0 0.0 7151.519\n",
      "0.0 0.0 7147.421\n",
      "1.6666667e-05 0.0 7144.5034\n",
      "1.6666667e-05 0.0 7142.6255\n",
      "3.3333334e-05 0.0 7140.2344\n",
      "0.0 0.0 7138.8994\n",
      "0.0 0.0 7137.719\n",
      "0.0 0.0 7136.717\n",
      "0.0 0.0 7135.7485\n",
      "0.0 0.0 7135.24\n",
      "0.0 0.0 7134.5835\n",
      "0.0 0.0 7133.6973\n",
      "0.0 0.0 7133.7935\n",
      "0.0 0.0 7132.9688\n",
      "0.0 0.0 7132.452\n",
      "0.0 0.0 7132.4087\n",
      "0.0 0.0 7131.6704\n",
      "[7421.765  8438.289  4808.6577 ... 5775.553  4974.0103 5157.831 ]\n"
     ]
    }
   ],
   "source": [
    "def get_accuracy(x, y, W):\n",
    "    return accuracy(mglu(x, W), y)\n",
    "\n",
    "get_accuracy_b = F(get_accuracy).vmap(in_axes=(0, 0, None), out_axes=0)\n",
    "get_accuracy_b_d = get_accuracy_b.f(X, y, _) >> mean\n",
    "get_accuracy_b_t = get_accuracy_b.f(X_test, y_test, _) >> mean\n",
    "\n",
    "for i in range(1000):\n",
    "    W, state = update(W, state)\n",
    "    if i % 50 == 0:\n",
    "        print(get_accuracy_b_d(W), get_accuracy_b_t(W), loss_b_d(W))\n",
    "print(loss_d(W))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
