{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../berries\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'my_datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmy_datasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Supervised1D, load_supervised_1d\n\u001b[1;32m      3\u001b[0m n_samples, d_x, d_y, X, y, X_test, y_test \u001b[38;5;241m=\u001b[39m load_supervised_1d(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmnist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'my_datasets'"
     ]
    }
   ],
   "source": [
    "from my_datasets import Supervised1D, load_supervised_1d\n",
    "\n",
    "n_samples, d_x, d_y, X, y, X_test, y_test = load_supervised_1d(\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / 255.0\n",
    "X_test = X_test / 255.0\n",
    "n_samples_test = X_test.shape[0]\n",
    "\n",
    "X = 2 * X - 1\n",
    "X_test = 2 * X_test - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_h_layer = 128\n",
    "d_h = 256\n",
    "n_g_layers = 8\n",
    "n_d_layers = 4\n",
    "d_in = d_x\n",
    "# d_out = d_y\n",
    "d_out = d_x\n",
    "d_z = 64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import importlib\n",
    "import nn\n",
    "importlib.reload(nn)\n",
    "import pf\n",
    "importlib.reload(pf)\n",
    "from nn import mglu_net_config, mglu_net, rmglu_net\n",
    "from pf import F, _\n",
    "from optax import sigmoid_binary_cross_entropy\n",
    "\n",
    "from jax.numpy import mean, exp, log, tanh, array\n",
    "from jax.nn import sigmoid, log_sigmoid\n",
    "\n",
    "\n",
    "# def gan_config(d_z, d_in, d_h_layer, d_h, n_g_layers, n_d_layers, init):\n",
    "#     return {\n",
    "#         \"generator\":mglu_net_config(d_z, d_h_layer, d_in, d_h, n_g_layers, init),\n",
    "#         \"discriminator\": mglu_net_config(d_in, d_h_layer, 1, d_h, n_d_layers, init)\n",
    "#     }\n",
    "\n",
    "\n",
    "\n",
    "generator = F(mglu_net).swap() >> tanh\n",
    "#discriminator = F(mglu_net).swap()\n",
    "def discriminator(W, x):\n",
    "    return mglu_net(x, W)\n",
    "\n",
    "\n",
    "def generator_value_and_loss(Wg, Wd, z):\n",
    "    X_gen = generator(Wg, z)\n",
    "    return X_gen, -log_sigmoid(discriminator(Wd, X_gen))\n",
    "\n",
    "def discriminator_loss_X(Wd, X_gen, X):\n",
    "    return sigmoid_binary_cross_entropy(discriminator(Wd, X), array(1)) + sigmoid_binary_cross_entropy(discriminator(Wd, X_gen), array(0))\n",
    "\n",
    "\n",
    "def discriminator_loss_z(W, X, z):\n",
    "    X_gen = generator(W['generator'], z)\n",
    "    return discriminator_loss_X(W['discriminator'], X_gen, X)\n",
    "\n",
    "\n",
    "d_loss_X_bm = F(discriminator_loss_X).vmap((None, 0, 0), 0) >> mean\n",
    "\n",
    "generator_b = generator.vmap((None, 0), 0)\n",
    "\n",
    "def g_val_loss_bm(Wg, Wd, z):\n",
    "    X_gen, loss = F(generator_value_and_loss).vmap((None, None, 0), 0)(Wg, Wd, z)\n",
    "    return mean(loss), X_gen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gan_config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m method \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzer0\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.001\u001b[39m}\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# method = {\"type\": \"normal\", \"std\": 0.01}\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m W \u001b[38;5;241m=\u001b[39m init_weights(\u001b[38;5;28mnext\u001b[39m(key_gen), \u001b[43mgan_config\u001b[49m(d_z, d_in, d_h_layer, d_h, n_g_layers, n_d_layers, method, method))\n\u001b[1;32m     24\u001b[0m d_loss0 \u001b[38;5;241m=\u001b[39m discriminator_loss_z(W,  X_test[\u001b[38;5;241m0\u001b[39m, :], get_noise_batch(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     25\u001b[0m Xp0, g_loss0 \u001b[38;5;241m=\u001b[39m generator_value_and_loss(W[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerator\u001b[39m\u001b[38;5;124m'\u001b[39m], W[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscriminator\u001b[39m\u001b[38;5;124m'\u001b[39m], get_noise_batch(\u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gan_config' is not defined"
     ]
    }
   ],
   "source": [
    "import optax\n",
    "from jax import grad, jit, value_and_grad\n",
    "from jax.tree_util import tree_map\n",
    "import random_utils\n",
    "import init_utils\n",
    "from nn import init_weights, fmt_weights\n",
    "from plot_utils import visualize_matrix\n",
    "\n",
    "seed = 0\n",
    "key_gen = random_utils.infinite_safe_keys(seed)\n",
    "\n",
    "\n",
    "def get_noise(size, key):\n",
    "    return init_utils.normal_init(key, sd=1., shape=size)\n",
    "\n",
    "def get_noise_batch(batch_size): \n",
    "    return get_noise([batch_size, d_z], next(key_gen))\n",
    "\n",
    "\n",
    "\n",
    "method = {\"type\": \"zer0\", \"std\": 0.001}\n",
    "# method = {\"type\": \"normal\", \"std\": 0.01}\n",
    "W = init_weights(next(key_gen), gan_config(d_z, d_in, d_h_layer, d_h, n_g_layers, n_d_layers, method, method))\n",
    "d_loss0 = discriminator_loss_z(W,  X_test[0, :], get_noise_batch(1))\n",
    "Xp0, g_loss0 = generator_value_and_loss(W['generator'], W['discriminator'], get_noise_batch(1))\n",
    "visualize_matrix(Xp0.reshape(28, 28), dpi=100)\n",
    "dx_loss0 = discriminator_loss_X(W['discriminator'], Xp0, X_test[0, :])\n",
    "\n",
    "print(dx_loss0, d_loss0, g_loss0)\n",
    "print(fmt_weights(W)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'W' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m opt_d \u001b[38;5;241m=\u001b[39m optax\u001b[38;5;241m.\u001b[39mmasked(optax\u001b[38;5;241m.\u001b[39madam(lr_d), mask_fn)\n\u001b[1;32m      8\u001b[0m opt_g \u001b[38;5;241m=\u001b[39m optax\u001b[38;5;241m.\u001b[39mmasked(optax\u001b[38;5;241m.\u001b[39mrmsprop(lr_g), mask_fn)\n\u001b[0;32m----> 9\u001b[0m state_gen \u001b[38;5;241m=\u001b[39m opt_g\u001b[38;5;241m.\u001b[39minit(\u001b[43mW\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     10\u001b[0m state_disc \u001b[38;5;241m=\u001b[39m opt_d\u001b[38;5;241m.\u001b[39minit(W[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiscriminator\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     11\u001b[0m opt_states \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator\u001b[39m\u001b[38;5;124m\"\u001b[39m: state_gen, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiscriminator\u001b[39m\u001b[38;5;124m\"\u001b[39m: state_disc}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'W' is not defined"
     ]
    }
   ],
   "source": [
    "import math, random\n",
    "\n",
    "lr_d = 0.005\n",
    "lr_g = 0.005\n",
    "mask_fn = lambda p: tree_map(lambda x: not isinstance(x, int), p)\n",
    "#opt = optax.masked(optax.rmsprop(lr), mask_fn)\n",
    "opt_d = optax.masked(optax.adam(lr_d), mask_fn)\n",
    "opt_g = optax.masked(optax.rmsprop(lr_g), mask_fn)\n",
    "state_gen = opt_g.init(W[\"generator\"])\n",
    "state_disc = opt_d.init(W[\"discriminator\"])\n",
    "opt_states = {\"generator\": state_gen, \"discriminator\": state_disc}\n",
    "@jit\n",
    "def update(W, x, z, opt_states):\n",
    "    (loss_g, xp), grad_g = value_and_grad(g_val_loss_bm, has_aux=True)(W['generator'], W['discriminator'], z)\n",
    "    g_updates, opt_state_g = opt_g.update(grad_g, opt_states['generator'])\n",
    "    wg = optax.apply_updates(W['generator'], g_updates)\n",
    "\n",
    "    loss_d, grad_d = value_and_grad(d_loss_X_bm)(W['discriminator'], xp, x)\n",
    "    d_updates, opt_state_d = opt_d.update(grad_d, opt_states['discriminator'])\n",
    "    wd = optax.apply_updates(W['discriminator'], d_updates)\n",
    "\n",
    "    return {\"discriminator\": wd, \"generator\": wg}, {\"discriminator\": opt_state_d, \"generator\": opt_state_g}, {\"discriminator\": loss_d, \"generator\": loss_g}\n",
    "\n",
    "\n",
    "@jit\n",
    "def update_g(W, x, z, g_opt_state):\n",
    "    (loss_g, xp), grad_g = value_and_grad(g_val_loss_bm, has_aux=True)(W['generator'], W['discriminator'], z)\n",
    "    g_updates, opt_state_g = opt_g.update(grad_g, g_opt_state)\n",
    "    wg = optax.apply_updates(W['generator'], g_updates)\n",
    "    return wg, opt_state_g, loss_g\n",
    "\n",
    "def sample(batch_size):\n",
    "    return X[random.sample(range(n_samples), batch_size), :]\n",
    "\n",
    "\n",
    "W0, opt_states0, losses = update(W, sample(2), get_noise([2, d_z], next(key_gen)), opt_states)\n",
    "print({k: v.item() for k, v in losses.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "image_width, image_length, image_channels = 28, 28, 1\n",
    "num_test_samples = 25 \n",
    "size_figure_grid = int(math.sqrt(num_test_samples))\n",
    "\n",
    "def display_samples(ax, image_matrix, num_samples=25):\n",
    "    for i, j in itertools.product(range(size_figure_grid), range(size_figure_grid)):\n",
    "        ax[i,j].get_xaxis().set_visible(False)\n",
    "        ax[i,j].get_yaxis().set_visible(False)\n",
    "    # reshaped_generated_images = fake_images.view(batch_size, 28, 28)\n",
    "    \n",
    "    for k in range(num_test_samples):\n",
    "        i = k // size_figure_grid\n",
    "        j = k % size_figure_grid\n",
    "        ax[i,j].cla()\n",
    "        ax[i,j].imshow(image_matrix[k,:].reshape(image_width, image_length), cmap='Greys_r')\n",
    "    \n",
    "def show_samples(x):\n",
    "    fig, ax = plt.subplots(size_figure_grid, size_figure_grid, figsize=(6, 6))\n",
    "    display_samples(ax, x[:num_test_samples], num_samples=num_test_samples)\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 38\u001b[0m\n\u001b[1;32m     34\u001b[0m discriminator_accuracy_b \u001b[38;5;241m=\u001b[39m F(discriminator_accuracy)\u001b[38;5;241m.\u001b[39mvmap((\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     35\u001b[0m discriminator_b \u001b[38;5;241m=\u001b[39m F(discriminator)\u001b[38;5;241m.\u001b[39mvmap((\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 38\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m(batch_size)\n\u001b[1;32m     39\u001b[0m z \u001b[38;5;241m=\u001b[39m get_noise_batch(batch_size)\n\u001b[1;32m     40\u001b[0m xp \u001b[38;5;241m=\u001b[39m generator_b(W[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerator\u001b[39m\u001b[38;5;124m'\u001b[39m], z)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample' is not defined"
     ]
    }
   ],
   "source": [
    "from jax.numpy import ones_like, zeros_like\n",
    "methodd = {\"type\": \"zer0\", \"std\": 0.001}\n",
    "method = {\"type\": \"normal\", \"std\": 0.01}\n",
    "def gan_config(d_z, d_in, d_h_layer, d_h, n_g_layers, n_d_layers, initd, initg):\n",
    "    return {\n",
    "        \"generator\":mglu_net_config(d_z, d_h_layer, d_in, d_h, n_g_layers, initd),\n",
    "        \"discriminator\": mglu_net_config(d_in, d_h_layer, 1, d_h, n_d_layers, initg)\n",
    "    }\n",
    "W = init_weights(next(key_gen), gan_config(d_z, d_in, d_h_layer, d_h, n_g_layers, n_d_layers, method, method))\n",
    "\n",
    "\n",
    "state_gen = opt_g.init(W[\"generator\"])\n",
    "state_disc = opt_d.init(W[\"discriminator\"])\n",
    "opt_states = {\"generator\": state_gen, \"discriminator\": state_disc}\n",
    "\n",
    "def discriminator_loss_X(Wd, X_gen, X):\n",
    "    return sigmoid_binary_cross_entropy(discriminator(Wd, X), array(1)) + sigmoid_binary_cross_entropy(discriminator(Wd, X_gen), array(0))\n",
    "\n",
    "d_loss_x_bm = F(discriminator_loss_X).vmap((None, 0, 0), 0) >> mean\n",
    "\n",
    "batch_size = 256\n",
    "@jit\n",
    "def update_d(wd, x, xp, d_opt_state):\n",
    "    grad_d = grad(d_loss_x_bm)(wd, xp, x)\n",
    "    d_updates, opt_state_d = opt_d.update(grad_d, d_opt_state)\n",
    "    wd = optax.apply_updates(wd, d_updates)\n",
    "    return wd, opt_state_d\n",
    "\n",
    "def discriminator_accuracy(Wd, X_gen, X):\n",
    "    gen = sigmoid(discriminator(Wd, X_gen))\n",
    "    real = sigmoid(discriminator(Wd, X))\n",
    "    return gen, real\n",
    "\n",
    "discriminator_accuracy_b = F(discriminator_accuracy).vmap((None, 0, 0), 0)\n",
    "discriminator_b = F(discriminator).vmap((None, 0), 0)\n",
    "\n",
    "\n",
    "data = sample(batch_size)\n",
    "z = get_noise_batch(batch_size)\n",
    "xp = generator_b(W['generator'], z)\n",
    "for i in range(50):\n",
    "    if i % 10 == 0:\n",
    "        W['discriminator'], opt_states['discriminator'] = update_d(W['discriminator'], data, xp, opt_states['discriminator'])\n",
    "        acc = discriminator_accuracy_b(W['discriminator'], xp, data)\n",
    "        loss = d_loss_X_bm(W['discriminator'], xp, data)\n",
    "        print(f\"loss {loss.item()}\")\n",
    "        print(f\"gen {acc[0].mean().item()} real {acc[1].mean().item()}\")\n",
    "\n",
    "# for i in range(500):\n",
    "#     W['generator'], opt_states['generator'], g_loss = update_g(W, data, get_noise_batch(batch_size), opt_states['generator'])\n",
    "#     if i % 100 == 0:\n",
    "#         print(f\"g_loss {g_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m50000\u001b[39m):\n\u001b[1;32m      8\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(key_gen)\n\u001b[0;32m----> 9\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m(batch_size)\n\u001b[1;32m     10\u001b[0m     xp \u001b[38;5;241m=\u001b[39m generator_b(W[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerator\u001b[39m\u001b[38;5;124m'\u001b[39m], z)\n\u001b[1;32m     11\u001b[0m     W[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscriminator\u001b[39m\u001b[38;5;124m'\u001b[39m], opt_states[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscriminator\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m update_d(W[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscriminator\u001b[39m\u001b[38;5;124m'\u001b[39m], data, xp, opt_states[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscriminator\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample' is not defined"
     ]
    }
   ],
   "source": [
    "import jax.numpy as np\n",
    "\n",
    "\n",
    "d_loss_bm_dt = F(discriminator_loss_z).vmap((None, 0, 0), 0).f(_, X_test, get_noise_batch(n_samples_test)) >> mean\n",
    "\n",
    "\n",
    "for i in range(50000):\n",
    "    key = next(key_gen)\n",
    "    data = sample(batch_size)\n",
    "    xp = generator_b(W['generator'], z)\n",
    "    W['discriminator'], opt_states['discriminator'] = update_d(W['discriminator'], data, xp, opt_states['discriminator'])\n",
    "    z = get_noise_batch(batch_size)\n",
    "    W, opt_states, losses = update(W, data, z, opt_states)\n",
    "\n",
    "    z = get_noise_batch(batch_size)\n",
    "    if i % 20 == 0:\n",
    "        acc = discriminator_accuracy_b(W['discriminator'], xp, data)\n",
    "        print({k: v.item() for k, v in losses.items()}, d_loss_bm_dt(W), acc[0].mean(), acc[1].mean())#, discriminator_accuracy_b(W['discriminator'], generator_b(W['generator'], z), X_test[:batch_size, :]))\n",
    "    if i % 500 == 0:\n",
    "        # plt, __, __ = visualize_matrix(data[image_id, :].reshape(28, 28), dpi=100)\n",
    "        # display(plt)\n",
    "\n",
    "        #outs = generator_b(W['generator'], z)\n",
    "        image_id = math.ceil(random.uniform(0, 1) * n_samples)\n",
    "        show_samples(xp)\n",
    "\n",
    "print(d_loss_bm_dt(W))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
