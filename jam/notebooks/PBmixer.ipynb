{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../berries\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random_utils\n",
    "seed = 0\n",
    "key_gen = random_utils.infinite_safe_keys(seed)\n",
    "\n",
    "from datasets import load_dataset\n",
    "cache_dir=\"$HOME/.cache/huggingface/datasets\"\n",
    "mnist = load_dataset(\"mnist\", cache_dir=cache_dir, trust_remote_code=True).with_format(\"jax\")\n",
    "mnistData = mnist['train']\n",
    "\n",
    "X_img = mnistData['image']\n",
    "y = mnistData['label']\n",
    "X_img_test = mnist[\"test\"][\"image\"]\n",
    "n_test_samples = X_img_test.shape[0]\n",
    "y_test = mnist[\"test\"][\"label\"]\n",
    "n_samples, _, _  = X_img.shape\n",
    "X_train = X_img.reshape((n_samples, 1, 28, 28))\n",
    "X_test = X_img_test.reshape((n_test_samples, 1, 28, 28))\n",
    "n_channels = 1\n",
    "d_x = (28, 28)\n",
    "d_y = len(set(y.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_samples = X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_mglu_h_layer = 128\n",
    "d_mglu_h = 128\n",
    "n_mglu_layers = 2\n",
    "\n",
    "n_mixer_layers = 2\n",
    "d_mixer_channels = 32\n",
    "\n",
    "d_encode_hidden = 64\n",
    "\n",
    "from jax.numpy import meshgrid, arange\n",
    "pos_x1, pos_x2 = meshgrid(arange(d_x[0]), arange(d_x[1]))\n",
    "pos_x1 = pos_x1.flatten()\n",
    "\n",
    "pos_x2 = pos_x2.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax.numpy import array, exp, mean\n",
    "import nn\n",
    "import importlib\n",
    "importlib.reload(nn)\n",
    "import pf\n",
    "importlib.reload(pf)\n",
    "from nn import mglu_net_config, mglu_net, sglu, sglu_config\n",
    "from pf import F, _\n",
    "import optax\n",
    "\n",
    "h_axis = 1\n",
    "x_axis = 0\n",
    "d_h_axis = d_mixer_channels\n",
    "d_x_axis = d_x[0] * d_x[1]\n",
    "\n",
    "def gaussian_activation(a, x):\n",
    "    return exp((-0.5 * x ** 2) / a ** 2)\n",
    "\n",
    "def pos_encode(W, x1, x2, v):\n",
    "    rep = array([x1, x2, v])\n",
    "    l1 = W['0'] @ rep\n",
    "    a = W['a']\n",
    "    a1 = gaussian_activation(a, l1)\n",
    "    return W['1'] @ a1\n",
    "\n",
    "def mixer_head(W, x):\n",
    "    val_flat = x.reshape(-1)\n",
    "    return F(pos_encode).vmap((None, 0, 0, 0), 0)(W, pos_x1, pos_x2, val_flat)\n",
    "\n",
    "\n",
    "def mixer_block(W, X):\n",
    "    mixer_h  = F(mglu_net).f(_, W['h']).vmap(x_axis, x_axis)\n",
    "    mixer_x = F(mglu_net).f(_, W['x']).vmap(h_axis, h_axis)\n",
    "    return X + mixer_h(X) + mixer_x(X)\n",
    "    \n",
    "\n",
    "def mixer(W, x):\n",
    "    X = mixer_head(W['head'], x)\n",
    "    for _ in range(n_mixer_layers):\n",
    "        X = mixer_block(W['block'], X)\n",
    "    return X\n",
    "\n",
    "def mixer_net(W, x):\n",
    "    X = mixer(W['mixer'], x) \n",
    "    return F(mglu_net).f(_, W['out'])(X.sum(axis=x_axis))\n",
    "\n",
    "mglu_net_conf_local = F(mglu_net_config).f(_, d_mglu_h_layer, _, d_mglu_h, n_mglu_layers, _)\n",
    "\n",
    "def mixer_block_config(init):\n",
    "    return {\n",
    "        'h': mglu_net_conf_local(d_h_axis, d_h_axis, init),\n",
    "        'x': mglu_net_conf_local(d_x_axis, d_x_axis, init)\n",
    "    }\n",
    "\n",
    "def mixer_head_config(init):\n",
    "    return {\n",
    "        'a': {\n",
    "            \"size\": (d_encode_hidden,),\n",
    "            \"const\": 1.0\n",
    "        },\n",
    "        '0': {\n",
    "            \"size\": ( d_encode_hidden, 3),\n",
    "            \"init\": init\n",
    "        },\n",
    "        '1': {\n",
    "            \"size\": (d_mixer_channels, d_encode_hidden),\n",
    "            \"init\": init\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "def mixer_config(init):\n",
    "    return {\n",
    "        'mixer': {\n",
    "            'head': mixer_head_config(init),\n",
    "            'block': mixer_block_config(init),\n",
    "        },\n",
    "        'out': mglu_net_conf_local(d_mixer_channels, d_y, init)\n",
    "            #sglu_config(d_mixer_channels, d_mglu_h,  d_y, init)\n",
    "    }\n",
    "\n",
    "def loss_1(W, x, y):\n",
    "    return optax.softmax_cross_entropy_with_integer_labels(mixer_net(W, x), y)\n",
    "\n",
    "loss_batch = F(loss_1).vmap((None, 0, 0), 0) >> F(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixer:\n",
      "    head:\n",
      "        a:\n",
      "            1.0\n",
      "        0:\n",
      "            array shape: (64, 3)\n",
      "        1:\n",
      "            array shape: (32, 64)\n",
      "        total params: 2241\n",
      "    block:\n",
      "        h:\n",
      "            mglu:\n",
      "                tuple:\n",
      "                    sglu:\n",
      "                        wv:\n",
      "                            array shape: (32, 128)\n",
      "                        wu:\n",
      "                            array shape: (32, 128)\n",
      "                        wo:\n",
      "                            array shape: (128, 128)\n",
      "                        total params: 24576\n",
      "                    rmsn:\n",
      "                        d:\n",
      "                            128.0\n",
      "                        total params: 1\n",
      "                    total params: 24577\n",
      "                tuple:\n",
      "                    sglu:\n",
      "                        wv:\n",
      "                            array shape: (128, 128)\n",
      "                        wu:\n",
      "                            array shape: (128, 128)\n",
      "                        wo:\n",
      "                            array shape: (128, 128)\n",
      "                        total params: 49152\n",
      "                    rmsn:\n",
      "                        d:\n",
      "                            128.0\n",
      "                        total params: 1\n",
      "                    total params: 49153\n",
      "                total params: 73730\n",
      "            sglu:\n",
      "                wv:\n",
      "                    array shape: (128, 128)\n",
      "                wu:\n",
      "                    array shape: (128, 128)\n",
      "                wo:\n",
      "                    array shape: (128, 32)\n",
      "                total params: 36864\n",
      "            total params: 110594\n",
      "        x:\n",
      "            mglu:\n",
      "                tuple:\n",
      "                    sglu:\n",
      "                        wv:\n",
      "                            array shape: (784, 128)\n",
      "                        wu:\n",
      "                            array shape: (784, 128)\n",
      "                        wo:\n",
      "                            array shape: (128, 128)\n",
      "                        total params: 217088\n",
      "                    rmsn:\n",
      "                        d:\n",
      "                            128.0\n",
      "                        total params: 1\n",
      "                    total params: 217089\n",
      "                tuple:\n",
      "                    sglu:\n",
      "                        wv:\n",
      "                            array shape: (128, 128)\n",
      "                        wu:\n",
      "                            array shape: (128, 128)\n",
      "                        wo:\n",
      "                            array shape: (128, 128)\n",
      "                        total params: 49152\n",
      "                    rmsn:\n",
      "                        d:\n",
      "                            128.0\n",
      "                        total params: 1\n",
      "                    total params: 49153\n",
      "                total params: 266242\n",
      "            sglu:\n",
      "                wv:\n",
      "                    array shape: (128, 128)\n",
      "                wu:\n",
      "                    array shape: (128, 128)\n",
      "                wo:\n",
      "                    array shape: (128, 784)\n",
      "                total params: 133120\n",
      "            total params: 399362\n",
      "        total params: 509956\n",
      "    total params: 512197\n",
      "out:\n",
      "    mglu:\n",
      "        tuple:\n",
      "            sglu:\n",
      "                wv:\n",
      "                    array shape: (32, 128)\n",
      "                wu:\n",
      "                    array shape: (32, 128)\n",
      "                wo:\n",
      "                    array shape: (128, 128)\n",
      "                total params: 24576\n",
      "            rmsn:\n",
      "                d:\n",
      "                    128.0\n",
      "                total params: 1\n",
      "            total params: 24577\n",
      "        tuple:\n",
      "            sglu:\n",
      "                wv:\n",
      "                    array shape: (128, 128)\n",
      "                wu:\n",
      "                    array shape: (128, 128)\n",
      "                wo:\n",
      "                    array shape: (128, 128)\n",
      "                total params: 49152\n",
      "            rmsn:\n",
      "                d:\n",
      "                    128.0\n",
      "                total params: 1\n",
      "            total params: 49153\n",
      "        total params: 73730\n",
      "    sglu:\n",
      "        wv:\n",
      "            array shape: (128, 128)\n",
      "        wu:\n",
      "            array shape: (128, 128)\n",
      "        wo:\n",
      "            array shape: (128, 10)\n",
      "        total params: 34048\n",
      "    total params: 107778\n",
      "total params: 619975\n",
      "\n",
      "2.333928\n"
     ]
    }
   ],
   "source": [
    "import optax\n",
    "from jax import grad, jit\n",
    "from jax.tree_util import tree_map\n",
    "from nn import init_weights, fmt_weights\n",
    "import init_utils\n",
    "\n",
    "\n",
    "\n",
    "lr = 0.001\n",
    "mask_fn = lambda p: tree_map(lambda x: not isinstance(x, int), p)\n",
    "# opt = optax.multi_transform({\"sgd\": optax.rmsprop(lr), \"zero\": optax.set_to_zero()}, mask_fn)\n",
    "opt = optax.masked(optax.adam(lr), mask_fn)\n",
    "\n",
    "method = {\"type\": \"zer0\", \"std\": 0.001}\n",
    "# method = {\"type\": \"normal\", \"std\": 0.01}\n",
    "# method = {\"type\": \"normal\", \"std\": 0.1}\n",
    "W = init_weights(next(key_gen), mixer_config(method))\n",
    "print(fmt_weights(W)[0])\n",
    "loss0 = loss_batch(W, X_test[:100, :], y_test[:100])\n",
    "print(loss0)\n",
    "state = opt.init(W)\n",
    "\n",
    "@jit\n",
    "def update(W, x, y, opt_state):\n",
    "    grads = grad(loss_batch)(W, x, y)\n",
    "    updates, opt_state = opt.update(grads, opt_state)\n",
    "    new_W = optax.apply_updates(W, updates)\n",
    "    return new_W, opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9296875 0.88189995 0.37824538\n",
      "0.96875 0.93549997 0.22289473\n",
      "0.9375 0.93619996 0.21310878\n",
      "0.953125 0.9514 0.17054951\n",
      "0.96875 0.9586 0.14123419\n",
      "0.984375 0.9601 0.13843772\n",
      "0.9921875 0.96019995 0.13538788\n",
      "0.984375 0.9644 0.12591325\n",
      "0.9765625 0.96529996 0.11703191\n",
      "1.0 0.9719 0.099137396\n",
      "0.9765625 0.9709 0.0986411\n",
      "0.9765625 0.9651 0.12225895\n",
      "0.984375 0.96919996 0.11409548\n",
      "1.0 0.97029996 0.104526915\n",
      "0.9921875 0.9704 0.09844821\n",
      "1.0 0.972 0.11032739\n",
      "1.0 0.9729 0.09602496\n",
      "1.0 0.97679996 0.091931865\n",
      "0.9921875 0.9693 0.1210527\n",
      "0.9921875 0.96989995 0.11904664\n",
      "0.984375 0.9729 0.10418497\n",
      "0.9921875 0.9727 0.09754897\n",
      "0.984375 0.97609997 0.08869575\n",
      "1.0 0.9744 0.09487423\n",
      "0.9921875 0.9719 0.10725566\n",
      "0.09044275\n"
     ]
    }
   ],
   "source": [
    "from plot_utils import visualize_matrix\n",
    "from IPython.display import display\n",
    "import math, random\n",
    "import jax.numpy as np\n",
    "\n",
    "\n",
    "def accuracy(logits, y):\n",
    "    return (logits.argmax(-1) == y).mean()\n",
    "\n",
    "def get_accuracy(x, y, W):\n",
    "    return accuracy(mixer_net(W, x), y)\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_index = random.sample(range(n_samples), batch_size * 2)\n",
    "test_index = random.sample(range(n_test_samples), batch_size * 2)\n",
    "\n",
    "get_accuracy_b = F(get_accuracy).vmap(in_axes=(0, 0, None), out_axes=0)\n",
    "get_accuracy_b_d = get_accuracy_b.f(X[train_index, :], y[array(train_index)], _) >> mean\n",
    "# get_accuracy_b_t = get_accuracy_b.f(X_test[test_index, :], y_test[array(test_index)], _) >> mean\n",
    "# get_accuracy_b_t = get_accuracy_b.f(X_test, y_test, _) >> mean\n",
    "\n",
    "@jit\n",
    "def get_accuracy_b_t(W):\n",
    "    n, val = 0, 0\n",
    "    for i in range(0, n_test_samples, batch_size):\n",
    "        real_batch_size = min(n_test_samples - i, batch_size)\n",
    "        acc_all = get_accuracy_b(X_test[i:i + batch_size, :], y_test[i:i + batch_size], W)\n",
    "        val +=  mean(acc_all) * real_batch_size\n",
    "        n += real_batch_size\n",
    "    return val / n\n",
    "\n",
    "@jit\n",
    "def loss_b_dt(W):\n",
    "    n, val = 0, 0\n",
    "    for i in range(0, n_test_samples, batch_size):\n",
    "        real_batch_size = min(n_test_samples - i, batch_size)\n",
    "        val += mean(loss_batch(W, X_test[i:i + batch_size, :], y_test[i:i + batch_size])) * real_batch_size\n",
    "        n += real_batch_size\n",
    "    return val / n\n",
    "\n",
    "\n",
    "\n",
    "def sample():\n",
    "    index = random.sample(range(n_samples), batch_size)\n",
    "    return X[index, :], y[array(index)]\n",
    "\n",
    "for i in range(10000):\n",
    "    xx, yy = sample()\n",
    "    W, state = update(W, xx, yy, state)\n",
    "    if i % 200 == 0:\n",
    "        print(mean(get_accuracy_b(xx, yy, W)), get_accuracy_b_t(W), loss_b_dt(W))\n",
    "\n",
    "\n",
    "print(loss_b_dt(W))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
