{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from jax import random, grad, jit, vmap, lax\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Helper functions for data loading and preprocessing\n",
    "cache_dir=\"~/.cache/huggingface/datasets\"\n",
    "\n",
    "def one_hot(x, k, dtype=jnp.float32):\n",
    "    \"\"\"Create a one-hot encoding of x of size k.\"\"\"\n",
    "    return jnp.array(x[:, None] == jnp.arange(k), dtype)\n",
    "\n",
    "\n",
    "\n",
    "def load_mnist_data():\n",
    "    \"\"\"Load and preprocess MNIST dataset using Hugging Face datasets with JAX format.\"\"\"\n",
    "    print(\"Loading MNIST dataset from Hugging Face with JAX format...\")\n",
    "    \n",
    "    # Load dataset from Hugging Face with JAX format\n",
    "    mnist_dataset = load_dataset(\"mnist\", cache_dir=cache_dir).with_format(\"jax\")\n",
    "    \n",
    "    # Extract train and test sets directly as JAX arrays\n",
    "    train_data = mnist_dataset[\"train\"]\n",
    "    test_data = mnist_dataset[\"test\"]\n",
    "    \n",
    "    # Extract images and reshape to 28x28\n",
    "    x_train = jnp.array([img.reshape(28, 28) for img in train_data[\"image\"]])\n",
    "    y_train = jnp.array(train_data[\"label\"])\n",
    "    \n",
    "    x_test = jnp.array([img.reshape(28, 28) for img in test_data[\"image\"]])\n",
    "    y_test = jnp.array(test_data[\"label\"])\n",
    "    \n",
    "    # Normalize data\n",
    "    x_train = x_train.astype(jnp.float32) / 255.0\n",
    "    x_test = x_test.astype(jnp.float32) / 255.0\n",
    "    \n",
    "    # Convert labels to one-hot encoding\n",
    "    y_train = one_hot(y_train, 10)\n",
    "    y_test = one_hot(y_test, 10)\n",
    "    \n",
    "    print(\"x_train shape:\", x_train.shape)\n",
    "    print(\"y_train shape:\", y_train.shape)\n",
    "    print(\"x_test shape:\", x_test.shape)\n",
    "    print(\"y_test shape:\", y_test.shape)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "def get_batch(key, x, y, batch_size):\n",
    "    \"\"\"Get a random batch from the dataset.\"\"\"\n",
    "    dataset_size = x.shape[0]\n",
    "    key, subkey = random.split(key)\n",
    "    indices = random.choice(subkey, dataset_size, (batch_size,), replace=False)\n",
    "    return x[indices], y[indices], key\n",
    "\n",
    "# Common utility functions\n",
    "def sigmoid(x):\n",
    "    \"\"\"Compute sigmoid function with clipping for numerical stability.\"\"\"\n",
    "    return 1.0 / (1.0 + jnp.exp(-jnp.clip(x, -30.0, 30.0)))\n",
    "\n",
    "def rmsnorm(x, gamma):\n",
    "    \"\"\"Root Mean Square Layer Normalization\"\"\"\n",
    "    epsilon = 1e-5  # Increased epsilon for stability\n",
    "    x_square = jnp.square(x)\n",
    "    mean_square = jnp.mean(x_square, axis=-1, keepdims=True)\n",
    "    # Add clipping to prevent division by very small numbers\n",
    "    denom = jnp.maximum(jnp.sqrt(mean_square + epsilon), epsilon)\n",
    "    x = x / denom\n",
    "    return x * gamma\n",
    "\n",
    "\n",
    "# Modify swiglu function - unchanged from original\n",
    "def swiglu(x, params):\n",
    "    \"\"\"\n",
    "    SwiGLU activation: SwiGLU(x) = Swish(xW_gate) âŠ— (xW_linear)\n",
    "    where Swish(x) = x * sigmoid(beta * x), with beta commonly set to 1.0\n",
    "    \"\"\"\n",
    "    gate = x @ params['W_gate']\n",
    "    linear = x @ params['W_linear']\n",
    "    \n",
    "    # Swish activation (x * sigmoid(x))\n",
    "    swish = gate * jax.nn.sigmoid(gate)\n",
    "    \n",
    "    # Element-wise product with linear projection\n",
    "    intermediate = swish * linear\n",
    "    \n",
    "    # Final projection\n",
    "    return intermediate @ params['W_out']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-Layer Diagonal RNN for Autoregressive MNIST Generation\n",
      "--------------------------------------------------------\n",
      "Loading MNIST dataset from Hugging Face with JAX format...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28)\n",
      "y_train shape: (60000, 10)\n",
      "x_test shape: (10000, 28, 28)\n",
      "y_test shape: (10000, 10)\n",
      "Initializing model parameters...\n",
      "Starting training for 40 epochs...\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import time\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "from jax import random, lax\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Modified loss function for autoregressive prediction with closest match\n",
    "def adaptive_loss_fn(params, forward_fn, batch_forward, x_batch):\n",
    "    \"\"\"\n",
    "    Compute loss for autoregressive prediction using closest match approach.\n",
    "    For each partially generated image, find the closest MNIST digit and\n",
    "    optimize towards that target.\n",
    "    \"\"\"\n",
    "    batch_size = x_batch.shape[0]\n",
    "    \n",
    "    # Function to find closest match for a partially generated image\n",
    "    def find_closest_match(partial_generated, dataset):\n",
    "        # We only compare the rows we've already generated\n",
    "        num_rows = partial_generated.shape[0]\n",
    "        \n",
    "        # Calculate MSE between the partial image and all dataset images (only for the generated rows)\n",
    "        partial_mse = jnp.mean((dataset[:, :num_rows, :] - partial_generated[jnp.newaxis, :, :]) ** 2, axis=(1, 2))\n",
    "        \n",
    "        # Find the index of the closest match\n",
    "        closest_idx = jnp.argmin(partial_mse)\n",
    "        return closest_idx\n",
    "    \n",
    "    # Function to compute loss for a single example\n",
    "    def compute_single_example_loss(single_x):\n",
    "        total_loss = 0.0\n",
    "        generated_rows = []\n",
    "        \n",
    "        # Generate the first row\n",
    "        # We need to initialize with a small random noise in the hidden state\n",
    "        # This is a simplified approach - in practice we'd use the RNN's inner mechanisms\n",
    "        if len(generated_rows) == 0:\n",
    "            # For the first row, there's no prior context, so we'll predict based on a zero row\n",
    "            # This is a simplification - ideally we'd use the model's actual initialization logic\n",
    "            dummy_input = jnp.zeros((1, single_x.shape[1]))\n",
    "            first_row_pred = forward_fn(params, dummy_input)[0]\n",
    "            generated_rows.append(first_row_pred)\n",
    "        \n",
    "        # Generate rows 1 to 27 sequentially\n",
    "        for i in range(1, 28):\n",
    "            # Stack the generated rows so far\n",
    "            partial_image = jnp.stack(generated_rows, axis=0)\n",
    "            \n",
    "            # Find the closest MNIST digit based on rows generated so far\n",
    "            closest_idx = find_closest_match(partial_image, x_batch)\n",
    "            \n",
    "            # Get the target next row from the closest match\n",
    "            target_next_row = x_batch[closest_idx, i, :]\n",
    "            \n",
    "            # Predict the next row based on generated rows so far\n",
    "            predicted_next_row = forward_fn(params, partial_image)[-1]\n",
    "            \n",
    "            # Add to loss (MSE between prediction and target)\n",
    "            row_loss = jnp.mean((predicted_next_row - target_next_row) ** 2)\n",
    "            total_loss += row_loss\n",
    "            \n",
    "            # Add the predicted row to our generated image\n",
    "            generated_rows.append(predicted_next_row)\n",
    "        \n",
    "        # Return average loss across all rows\n",
    "        return total_loss / 27  # Divide by number of rows we predicted\n",
    "    \n",
    "    # Map over the batch\n",
    "    example_losses = jnp.array([compute_single_example_loss(x_batch[i]) for i in range(batch_size)])\n",
    "    \n",
    "    # Return average loss across batch\n",
    "    return jnp.mean(example_losses)\n",
    "\n",
    "# Modified accuracy for image generation (using PSNR with closest match)\n",
    "def adaptive_psnr_fn(params, forward_fn, batch_forward, x_batch):\n",
    "    \"\"\"\n",
    "    Compute PSNR for autoregressively predicted images using closest match approach.\n",
    "    For each generated image, find the closest MNIST digit in the training set and\n",
    "    compute PSNR against that target.\n",
    "    \"\"\"\n",
    "    batch_size = min(x_batch.shape[0], 100)  # Limit to 100 examples for efficiency\n",
    "    x_sample = x_batch[:batch_size]\n",
    "    \n",
    "    # Generate images from scratch\n",
    "    generated_images = jnp.zeros((batch_size, 28, 28))\n",
    "    \n",
    "    # Get hidden state dimensions from params\n",
    "    hidden_size = params['diag_weights'].shape[0]\n",
    "    \n",
    "    # Define function to generate first row from a small random hidden state\n",
    "    def generate_row_from_hidden(params, h1, h2):\n",
    "        # Apply SwiGLU and output transformation\n",
    "        h1_transformed = swiglu(h1, params)\n",
    "        output = jnp.dot(h1_transformed, params['Wo']) + params['bo']\n",
    "        return jnp.clip(output, 0.0, 1.0)\n",
    "    \n",
    "    # Generate first row for each image\n",
    "    for j in range(batch_size):\n",
    "        # Small random hidden state (deterministic seed for reproducibility)\n",
    "        h1 = jnp.zeros(hidden_size) + 0.01 * jnp.sin(jnp.arange(hidden_size) + j)\n",
    "        h2 = jnp.zeros(hidden_size) + 0.01 * jnp.cos(jnp.arange(hidden_size) + j)\n",
    "        \n",
    "        # Generate first row\n",
    "        first_row = generate_row_from_hidden(params, h1, h2)\n",
    "        generated_images = generated_images.at[j, 0, :].set(first_row)\n",
    "        \n",
    "        # Generate remaining rows\n",
    "        for i in range(1, 28):\n",
    "            prev_rows = generated_images[j, :i, :]\n",
    "            next_row = forward_fn(params, prev_rows)[-1]\n",
    "            generated_images = generated_images.at[j, i, :].set(next_row)\n",
    "    \n",
    "    # Find closest MNIST digit for each generated image\n",
    "    def find_closest_image(generated_img):\n",
    "        mse = jnp.mean((x_batch - generated_img[jnp.newaxis, :, :]) ** 2, axis=(1, 2))\n",
    "        closest_idx = jnp.argmin(mse)\n",
    "        return closest_idx, mse[closest_idx]\n",
    "    \n",
    "    # Compute MSE and PSNR against closest matches\n",
    "    total_psnr = 0.0\n",
    "    for j in range(batch_size):\n",
    "        closest_idx, min_mse = find_closest_image(generated_images[j])\n",
    "        psnr = 20 * jnp.log10(1.0) - 10 * jnp.log10(min_mse)\n",
    "        total_psnr += psnr\n",
    "    \n",
    "    # Return average PSNR\n",
    "    return total_psnr / batch_size\n",
    "\n",
    "\n",
    "\n",
    "# Adapt the data loading for autoregressive task\n",
    "def load_mnist_data_autoregressive():\n",
    "    \"\"\"Adapt the MNIST data for autoregressive prediction.\"\"\"\n",
    "    x_train, _, x_test, _ = load_mnist_data()\n",
    "    \n",
    "    # We only need the image data for autoregressive prediction\n",
    "    return x_train, x_test\n",
    "\n",
    "# Helper function to get batches\n",
    "def get_batch(key, x, batch_size):\n",
    "    \"\"\"Get a random batch from x.\"\"\"\n",
    "    dataset_size = x.shape[0]\n",
    "    key, subkey = random.split(key)\n",
    "    indices = random.choice(subkey, dataset_size, (batch_size,), replace=False)\n",
    "    return x[indices], key\n",
    "\n",
    "# Modify the forward function for autoregressive prediction\n",
    "def two_layer_fused_scan_forward_fn(params, x_seq):\n",
    "    \"\"\"\n",
    "    A more efficient implementation that fuses both layers into a single scan.\n",
    "    Uses SwiGLU for the layer-to-layer transformation.\n",
    "    Modified to return predictions for the next row at each step.\n",
    "    \"\"\"\n",
    "    hidden_size = params['diag_weights'].shape[0]\n",
    "    diag_weights = params['diag_weights']\n",
    "    \n",
    "    # Define a function that processes both layers for a single timestep\n",
    "    def two_layer_step(carry, x):\n",
    "        h1, h2 = carry\n",
    "        \n",
    "        # Layer 1\n",
    "        input_proj1 = jnp.dot(x, params['Wxh'])\n",
    "        recurrent_proj1 = h1 * diag_weights\n",
    "        h1_new = input_proj1 + recurrent_proj1\n",
    "        \n",
    "        # Apply SwiGLU to connect layer 1 to layer 2\n",
    "        h1_transformed = swiglu(h1_new, params)\n",
    "        \n",
    "        # Layer 2\n",
    "        recurrent_proj2 = h2 * diag_weights\n",
    "        h2_new = h1_transformed + recurrent_proj2\n",
    "        \n",
    "        # Generate output for this time step (predict next row)\n",
    "        output = jnp.dot(h2_new, params['Wo']) + params['bo']\n",
    "        \n",
    "        return (h1_new, h2_new), output\n",
    "    \n",
    "    # Initialize both hidden states\n",
    "    init_states = (jnp.zeros(hidden_size), jnp.zeros(hidden_size))\n",
    "    \n",
    "    # Process the entire sequence with a single scan\n",
    "    _, outputs = lax.scan(\n",
    "        f=two_layer_step,\n",
    "        init=init_states,\n",
    "        xs=x_seq\n",
    "    )\n",
    "    \n",
    "    # Return the predicted next rows\n",
    "    return outputs\n",
    "\n",
    "# Modify parameter initialization for autoregressive task\n",
    "def diagonal_init_params(key):\n",
    "    \"\"\"Initialize parameters for a 2-layer diagonal RNN with SwiGLU between layers.\"\"\"\n",
    "    hidden_size = 128\n",
    "    features = 28   # MNIST image width\n",
    "    output_size = 28  # Output is a full row of pixels\n",
    "    intermediate_size = 128  # Size for the SwiGLU intermediate representation\n",
    "    \n",
    "    # Initialization scale\n",
    "    init_scale = 0.01\n",
    "    \n",
    "    k1, k2, k3, k4, k5 = random.split(key, 5)\n",
    "    \n",
    "    return {\n",
    "        # First layer parameters\n",
    "        'Wxh': random.normal(k1, (features, hidden_size)) * init_scale,\n",
    "        \n",
    "        # Shared diagonal weights for recurrent connections in both layers\n",
    "        'diag_weights': random.normal(k2, (hidden_size,)) * init_scale,\n",
    "        \n",
    "        # SwiGLU parameters for layer-to-layer transition\n",
    "        'W_gate': random.normal(k3, (hidden_size, intermediate_size)) * init_scale,\n",
    "        'W_linear': random.normal(k4, (hidden_size, intermediate_size)) * init_scale,\n",
    "        'W_out': random.normal(k5, (intermediate_size, hidden_size)) * init_scale,\n",
    "        \n",
    "        # Output layer (predicts a row of pixels)\n",
    "        'Wo': random.normal(k2, (hidden_size, output_size)) * init_scale,\n",
    "        'bo': jnp.zeros(output_size)\n",
    "    }\n",
    "\n",
    "# Core evaluation function modified for adaptive autoregressive task\n",
    "def evaluate_model(init_params_fn, forward_fn, epochs=5, batch_size=64, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Evaluate an RNN architecture for autoregressive image generation with adaptive closest match approach.\n",
    "    \n",
    "    Args:\n",
    "        init_params_fn: Function that initializes model parameters\n",
    "        forward_fn: Function that performs forward pass on a batch of data\n",
    "        epochs: Number of training epochs\n",
    "        batch_size: Training batch size\n",
    "        learning_rate: Learning rate for optimizer\n",
    "        \n",
    "    Returns:\n",
    "        trained_params: The trained model parameters\n",
    "        metrics: Dictionary containing training history and evaluation metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    x_train, x_test = load_mnist_data_autoregressive()\n",
    "    \n",
    "    # Get PRNGKey for reproducibility\n",
    "    key = random.PRNGKey(42)\n",
    "    \n",
    "    # Initialize parameters\n",
    "    print(\"Initializing model parameters...\")\n",
    "    params = init_params_fn(key)\n",
    "    \n",
    "    # Create optimizer\n",
    "    optimizer = optax.adam(learning_rate)\n",
    "    opt_state = optimizer.init(params)\n",
    "    \n",
    "    # JIT-compile the forward function\n",
    "    batch_forward = jax.jit(jax.vmap(forward_fn, in_axes=(None, 0)))\n",
    "    \n",
    "    # Define update step with adaptive loss\n",
    "    @jax.jit\n",
    "    def update_step(params, opt_state, x_batch):\n",
    "        \"\"\"Perform a single update step using adaptive closest match loss.\"\"\"\n",
    "        def batch_loss(p):\n",
    "            return adaptive_loss_fn(p, forward_fn, batch_forward, x_batch)\n",
    "            \n",
    "        loss_value, grads = jax.value_and_grad(batch_loss)(params)\n",
    "        updates, new_opt_state = optimizer.update(grads, opt_state)\n",
    "        new_params = optax.apply_updates(params, updates)\n",
    "        return new_params, new_opt_state, loss_value\n",
    "    \n",
    "    # Training loop\n",
    "    print(f\"Starting training for {epochs} epochs...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_losses = []\n",
    "    train_psnrs = []\n",
    "    val_psnrs = []\n",
    "    \n",
    "    # Use a smaller validation set\n",
    "    val_size = 1000\n",
    "    val_x = x_test[:val_size]\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_losses = []\n",
    "        \n",
    "        # Number of batches per epoch\n",
    "        num_batches = x_train.shape[0] // batch_size\n",
    "        \n",
    "        for batch in range(num_batches):\n",
    "            # Get batch\n",
    "            x_batch, key = get_batch(key, x_train, batch_size)\n",
    "            \n",
    "            # Update parameters\n",
    "            params, opt_state, loss_value = update_step(params, opt_state, x_batch)\n",
    "            epoch_losses.append(loss_value)\n",
    "            \n",
    "            # Print progress occasionally\n",
    "            if batch % 100 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{epochs}, Batch {batch}/{num_batches}, Loss: {loss_value:.4f}\")\n",
    "        \n",
    "        # Compute epoch metrics\n",
    "        avg_loss = jnp.mean(jnp.array(epoch_losses))\n",
    "        train_losses.append(float(avg_loss))\n",
    "        \n",
    "        # Compute validation PSNR with adaptive metric\n",
    "        val_psnr = adaptive_psnr_fn(params, forward_fn, batch_forward, val_x)\n",
    "        val_psnrs.append(float(val_psnr))\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs} completed. Avg Loss: {avg_loss:.4f}, Val PSNR: {val_psnr:.2f} dB\")\n",
    "    \n",
    "    # Compute final test PSNR using adaptive metric\n",
    "    test_psnr = adaptive_psnr_fn(params, forward_fn, batch_forward, x_test)\n",
    "    print(f\"Final test PSNR: {test_psnr:.2f} dB\")\n",
    "    \n",
    "    # Compute training time\n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"Training completed in {training_time:.2f} seconds.\")\n",
    "    \n",
    "    # Return the trained parameters and metrics\n",
    "    metrics = {\n",
    "        'train_losses': train_losses,\n",
    "        'val_psnrs': val_psnrs,\n",
    "        'test_psnr': float(test_psnr),\n",
    "        'training_time': training_time\n",
    "    }\n",
    "    \n",
    "    return params, metrics\n",
    "\n",
    "# Generate MNIST images from scratch\n",
    "def generate_images_from_scratch(params, forward_fn, num_images=5, seed=42):\n",
    "    \"\"\"\n",
    "    Generate MNIST images completely from scratch using the trained RNN model.\n",
    "    Uses a small initial hidden state and generates all rows including the first.\n",
    "    \n",
    "    Args:\n",
    "        params: Trained model parameters\n",
    "        forward_fn: Model forward function\n",
    "        num_images: Number of images to generate\n",
    "        seed: Random seed\n",
    "        \n",
    "    Returns:\n",
    "        Array of generated images\n",
    "    \"\"\"\n",
    "    # Initialize random key\n",
    "    key = random.PRNGKey(seed)\n",
    "    \n",
    "    # Initialize images with zeros\n",
    "    generated_images = jnp.zeros((num_images, 28, 28))\n",
    "    \n",
    "    # Get hidden state dimensions from params\n",
    "    hidden_size = params['diag_weights'].shape[0]\n",
    "    \n",
    "    # Define a function that generates a row directly from the hidden state\n",
    "    def generate_row_from_hidden(params, hidden_state):\n",
    "        \"\"\"Generate a row directly from a hidden state.\"\"\"\n",
    "        # Apply SwiGLU to transform hidden state\n",
    "        hidden_transformed = swiglu(hidden_state[0], params)\n",
    "        \n",
    "        # Generate output\n",
    "        output = jnp.dot(hidden_transformed, params['Wo']) + params['bo']\n",
    "        return jnp.clip(output, 0.0, 1.0)  # Clip to valid pixel range\n",
    "    \n",
    "    # For each image\n",
    "    for j in range(num_images):\n",
    "        # Create a small initial hidden state\n",
    "        key, subkey = random.split(key)\n",
    "        h1 = random.normal(subkey, (hidden_size,)) * 0.01\n",
    "        \n",
    "        key, subkey = random.split(key)\n",
    "        h2 = random.normal(subkey, (hidden_size,)) * 0.01\n",
    "        \n",
    "        # Generate the first row directly from hidden state\n",
    "        first_row = generate_row_from_hidden(params, (h1, h2))\n",
    "        generated_images = generated_images.at[j, 0, :].set(first_row)\n",
    "        \n",
    "        # Now use the RNN to generate subsequent rows\n",
    "        # Create a single-sample forward function\n",
    "        def forward_one_row(params, prev_rows):\n",
    "            \"\"\"Forward pass to generate a single row based on previous rows.\"\"\"\n",
    "            prediction = forward_fn(params, prev_rows)\n",
    "            return prediction[-1]\n",
    "        \n",
    "        # Generate rows 1-27 autoregressively\n",
    "        for i in range(1, 28):\n",
    "            # Get previously generated rows\n",
    "            prev_rows = generated_images[j, :i, :]\n",
    "            \n",
    "            # Predict the next row\n",
    "            next_row = forward_one_row(params, prev_rows)\n",
    "            \n",
    "            # Update the image with the new row\n",
    "            generated_images = generated_images.at[j, i, :].set(next_row)\n",
    "    \n",
    "    return generated_images\n",
    "\n",
    "# Visualize generated images with their closest MNIST matches\n",
    "def visualize_generations_with_closest_matches(generated_images, mnist_images):\n",
    "    \"\"\"\n",
    "    Visualize comparison between generated images and their closest MNIST matches.\n",
    "    \n",
    "    Args:\n",
    "        generated_images: Images generated from scratch\n",
    "        mnist_images: Dataset of real MNIST images to find matches in\n",
    "    \"\"\"\n",
    "    num_to_show = len(generated_images)\n",
    "    \n",
    "    # Function to find closest match for a generated image\n",
    "    def find_closest_match(generated_img, real_imgs):\n",
    "        # Calculate mean squared error between the generated image and all real images\n",
    "        mse = np.mean((real_imgs - generated_img[np.newaxis, :, :]) ** 2, axis=(1, 2))\n",
    "        # Find the index of the closest match\n",
    "        closest_idx = np.argmin(mse)\n",
    "        return closest_idx, mse[closest_idx]\n",
    "    \n",
    "    plt.figure(figsize=(12, 2*num_to_show))\n",
    "    \n",
    "    for i in range(num_to_show):\n",
    "        # Find the closest match in the MNIST dataset\n",
    "        closest_idx, mse_score = find_closest_match(np.array(generated_images[i]), np.array(mnist_images))\n",
    "        \n",
    "        # Generated image\n",
    "        plt.subplot(num_to_show, 2, 2*i + 1)\n",
    "        plt.imshow(generated_images[i], cmap='gray')\n",
    "        plt.title(f\"Generated\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Closest match\n",
    "        plt.subplot(num_to_show, 2, 2*i + 2)\n",
    "        plt.imshow(mnist_images[closest_idx], cmap='gray')\n",
    "        plt.title(f\"Closest MNIST Match\\nMSE: {mse_score:.4f}\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize row-by-row generation\n",
    "def visualize_generation_process(params, forward_fn, seed=42):\n",
    "    \"\"\"\n",
    "    Visualize the row-by-row generation process of a single image from scratch.\n",
    "    \"\"\"\n",
    "    # Generate a single image and show the progression\n",
    "    key = random.PRNGKey(seed)\n",
    "    \n",
    "    # Initialize image with zeros\n",
    "    generated_image = jnp.zeros((28, 28))\n",
    "    \n",
    "    # Get hidden state dimensions from params\n",
    "    hidden_size = params['diag_weights'].shape[0]\n",
    "    \n",
    "    # Create a small initial hidden state\n",
    "    key, subkey = random.split(key)\n",
    "    h1 = random.normal(subkey, (hidden_size,)) * 0.01\n",
    "    \n",
    "    key, subkey = random.split(key)\n",
    "    h2 = random.normal(subkey, (hidden_size,)) * 0.01\n",
    "    \n",
    "    # Define a function that generates a row directly from the hidden state\n",
    "    def generate_row_from_hidden(params, hidden_state):\n",
    "        \"\"\"Generate a row directly from a hidden state.\"\"\"\n",
    "        # Apply SwiGLU to transform hidden state\n",
    "        hidden_transformed = swiglu(hidden_state[0], params)\n",
    "        \n",
    "        # Generate output\n",
    "        output = jnp.dot(hidden_transformed, params['Wo']) + params['bo']\n",
    "        return jnp.clip(output, 0.0, 1.0)  # Clip to valid pixel range\n",
    "    \n",
    "    # Generate the first row directly from hidden state\n",
    "    first_row = generate_row_from_hidden(params, (h1, h2))\n",
    "    generated_image = generated_image.at[0, :].set(first_row)\n",
    "    \n",
    "    # Create a function to generate a single row\n",
    "    def forward_one_row(params, prev_rows):\n",
    "        \"\"\"Forward pass to generate a single row based on previous rows.\"\"\"\n",
    "        prediction = forward_fn(params, prev_rows)\n",
    "        return prediction[-1]\n",
    "    \n",
    "    # Generate each row autoregressively and save intermediate states\n",
    "    intermediate_images = [generated_image.copy()]\n",
    "    \n",
    "    for i in range(1, 28):\n",
    "        # Get previously generated rows\n",
    "        prev_rows = generated_image[:i, :]\n",
    "        \n",
    "        # Predict the next row\n",
    "        next_row = forward_one_row(params, prev_rows)\n",
    "        \n",
    "        # Update the image with the new row\n",
    "        generated_image = generated_image.at[i, :].set(next_row)\n",
    "        \n",
    "        # Save the intermediate state\n",
    "        intermediate_images.append(generated_image.copy())\n",
    "    \n",
    "    # Plot selected intermediate states\n",
    "    steps_to_show = [0, 4, 9, 14, 19, 27]  # First row, 25%, 50%, 75%, 100%\n",
    "    \n",
    "    plt.figure(figsize=(15, 3))\n",
    "    for i, step in enumerate(steps_to_show):\n",
    "        plt.subplot(1, len(steps_to_show), i+1)\n",
    "        plt.imshow(intermediate_images[step], cmap='gray')\n",
    "        plt.title(f\"After {step+1} rows\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Two-Layer Diagonal RNN for Autoregressive MNIST Generation\")\n",
    "    print(\"--------------------------------------------------------\")\n",
    "    \n",
    "    forward_fn = two_layer_fused_scan_forward_fn\n",
    "    \n",
    "    # Evaluate model\n",
    "    trained_params, metrics = evaluate_model(\n",
    "        init_params_fn=diagonal_init_params,\n",
    "        forward_fn=forward_fn,\n",
    "        epochs=40,\n",
    "        batch_size=64,\n",
    "        learning_rate=0.0005\n",
    "    )\n",
    "    \n",
    "    print(\"Evaluation complete!\")\n",
    "    print(f\"Test PSNR: {metrics['test_psnr']:.2f} dB\")\n",
    "    print(f\"Training time: {metrics['training_time']:.2f} seconds\")\n",
    "    \n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(metrics['train_losses'])\n",
    "    plt.title('Training Loss (MSE)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(metrics['val_psnrs'])\n",
    "    plt.title('Validation PSNR')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('PSNR (dB)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Generate images completely from scratch\n",
    "    print(\"\\nGenerating new images completely from scratch...\")\n",
    "    generated_images = generate_images_from_scratch(\n",
    "        params=trained_params, \n",
    "        forward_fn=forward_fn,\n",
    "        num_images=5\n",
    "    )\n",
    "    \n",
    "    # Get full MNIST dataset for finding closest matches\n",
    "    _, _, x_test, _ = load_mnist_data()\n",
    "    \n",
    "    # Visualize generated vs closest MNIST images\n",
    "    visualize_generations_with_closest_matches(generated_images, x_test)\n",
    "    \n",
    "    # Visualize the row-by-row generation process\n",
    "    print(\"\\nVisualizing the row-by-row generation process...\")\n",
    "    visualize_generation_process(trained_params, forward_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
